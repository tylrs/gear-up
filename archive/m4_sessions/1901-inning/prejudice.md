## Group Members:
Tanjie, Melvin, Derek, Harper

## Name of Session: 
Prejudice

## Session Description 
Turing's mission is to unlock human potential by training a diverse, inclusive student body to succeed in high-fulfillment technical careers. In this session we will identify, examine, and discuss our prejudices, biases, and our related experiences with the aim of creating concrete actionable solution to make tech and our broader communities more (inclusive**?)

## Session Outcomes 
(What will students learn/leave with?): 
Students will leave with a concrete plan for address their own biases and those of others in the wild

## Session Outline
* Intros (5-10 mins) Let students settle in the space, an icebreaker where each student writes an interesting fact about themselves on a piece of paper and puts it in a hat. Papers are drawn by a facilitator, the fact is read aloud and the group tries to guess who submitted the fact.  Norms and expectations will then be outlined. 

* Implicit Bias Tests (10 - 15 mins) Students will need to bring a computer to this session.  Facilitators will choose four implicit bias tests.  Students will be randomly assigned to take one of the four test, and time permitting, will be able to another bias test of their choosing. Students will be given a few minutes to reflect on the finding either in a journal or just to themselves.

* Small Group Discussion (15 mins) Students will break into small groups determined by the randomly assigned bias test (eg, those who took the bias around disabilities test will group together, those who took the racial biases test will group, etc.
The facilitators will write discussion questions on the white board in order to lead focused discussion. All facilitators will have taken a bias test beforehand, and will be prepared to speak aobut their experiences while taking it with their groups.

* Recap and Segue (5 min) Come back together to a larger group, where facilitators will invite students to share insights from their break out discussions.  Facilitator will then provide a link to short article on bias in technology (Article currently TBD, but will center around bias in AI, eg, the racist twitter bot).

* Time allotment for reading the article (5 min)

* Discussion (20 mins) led by all 3 group members.  Discuss how this related to tech.  Start with broad example like racist twitterbot and then bring it down to a more personal level with examples from Turing.  Ask what are steps to take when things like this happen in your community.  Brainstorm potential reactions/actions to be better prepared to confont bias when it presents itself. 

## Norms
* Listen
* Take people's stories at face value - no questioning authenticity/experience
* Check reactions when listening - don't make the story about you when it's someone else's story
* Frame when/how to use words that may be offensive - leaders give personal example
* Suggest parking lot for later discussions

## Questions for Small Groups
* what tests did you take?
* did your results surprise you?
* Do you have internalized prejudice? (If you took a test that you share a diversty marker with)
* When have you been a target of prejudice?  Alternately, when have you been complicit (through action or inaction)?

## Larger Group Takeaways
* If someone confronts you about a particular situation where they felt marginalized and you contributed to this feeling, don't make them process your feelings about the situation.  It's not their job to comfort you, it's your job to listen, and take feedback.
* Turing is not immune to biases and prejudice.  It happens here. 
* If you have identified a prejudice you hold, what can you actively do to counteract or stop it? (short term counteracted by being exposed to alternatives to their particular prejudice - seek out things that challenge your particular bias)
## Materials
[Harvard's Implicit Bias Test](https://implicit.harvard.edu/implicit/takeatest.html)

And One of the following:

[The Guardian - AI programs exhibit racial and gender biases, research reveals](https://www.theguardian.com/technology/2017/apr/13/ai-programs-exhibit-racist-and-sexist-biases-research-reveals)

[The impact of gender and race bias in AI](https://blogs.icrc.org/law-and-policy/2018/08/28/impact-gender-race-bias-ai/)

[Artificial Intelligence Has a Bias Problem, and It's Our Fault](https://www.pcmag.com/article/361661/artificial-intelligence-has-a-bias-problem-and-its-our-fau)

[Unmasking A.I.'s Bias Problem](http://fortune.com/longform/ai-bias-problem/)


## Group Notes from 1/25
**Learning Goals**
At the end of this session, students will be able to-
  1. Acknowledge that bias is inherent in all of our perspectives.
  2. Help students verbalize the impact of sterotyping or personal bias in tech.
  3. Recognize self-reflection as a method for understanding one's own biases.
  4. List strategies for eliminating bias in tech. 


**Materials & Resources** 
- Personal computers
- Slack group with shared link to the implicit bias test shared beforehand
- 15-20 slips of paper with an implicit bias test written on it (race, gender and/or disability) 
- [Article on implict bias in tech](https://www.pcmag.com/article/361661/artificial-intelligence-has-a-bias-problem-and-its-our-fau)
- Google slides with learning outcomes and norms to be posted on airplay during Gear Up


**Norms**
- Listen.
- Use "I" statements 
- Take people's stories at face value - don't question the authenticity of someone's experience
- Don't make the story about you (be aware of how interpersonal relationships reflect larger societal issues) 
- Respect each other 
- Be nice 
- Seek to be informative and educate rather than accusatory 


**Icebreakers**
1. Which tv show would you pick to live inside for a week?
2. What would be on the menu for your ultimate birthday dinner? 
3. What would you do for fun if you had to give up the internet for a week?
4. What personality trait has gotten you in the most trouble? 


**Discussion Questions**
Small group reflection-
  1. How do you feel about your result? Did you get the result that you expected? Were you completely surprised? 
  2. Did you find the result of your test helpful? Is it counter-productive?
  3. Do you think you have internalized prejudice? 
  4. Have you ever been the target of prejudice? Have you ever been complicit in a bias (through action or being a bystander)? 
Whole group reflection-
  1. Share any insights from your small group discussion? 
  2. Where do you think your implicit bias comes from? Your culture? Enviornment? Yourself? 
  3. What do you think about being "blind" to race/gender discrimination? 
  4. If you have identified a prejudice you hold, what can you actively do to counteract or stop it? 
  5. Let's think of strategies for dismantling implicit bias in the tech industry. 


**Timeline**
Students walk in and take an annoymous test from the fishbowl that they can't look at (5 min)
Icebreaker questions/introductions with facilitators leading (pronouns, mod and ask/answer icebreaker) (5 min)
State learning goals (5 min)
Help students set up their computers and take the Implicit Bias Test (15 min) 
Allow students who have finished to take a POM (5 min)
Small group discussion (10 min)
Large group discussion (15 min) 
Closing and share reading resources to learn more about implicit biases in tech in slack channel (5 min)



Submit a PR at the end of this session and tag @emhickmann
